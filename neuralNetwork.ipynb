{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d7fdc042",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5cb9731b",
   "metadata": {},
   "source": [
    "Obtaining data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "217d15ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>liczba pokoi</th>\n",
       "      <th>pow przynależna</th>\n",
       "      <th>pu lokalu</th>\n",
       "      <th>cena mkw</th>\n",
       "      <th>road_distance</th>\n",
       "      <th>road_time</th>\n",
       "      <th>kondygnacja</th>\n",
       "      <th>odl bagatela</th>\n",
       "      <th>odl dworzec</th>\n",
       "      <th>odl lotnisko</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>43.41</td>\n",
       "      <td>10827.00</td>\n",
       "      <td>5613</td>\n",
       "      <td>1056</td>\n",
       "      <td>2</td>\n",
       "      <td>4.248644</td>\n",
       "      <td>4.369925</td>\n",
       "      <td>8.979016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>41.57</td>\n",
       "      <td>12244.41</td>\n",
       "      <td>7479</td>\n",
       "      <td>977</td>\n",
       "      <td>3</td>\n",
       "      <td>4.141580</td>\n",
       "      <td>4.479480</td>\n",
       "      <td>8.267711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>56.99</td>\n",
       "      <td>11335.32</td>\n",
       "      <td>5754</td>\n",
       "      <td>1083</td>\n",
       "      <td>3</td>\n",
       "      <td>4.356337</td>\n",
       "      <td>4.443816</td>\n",
       "      <td>9.070740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>42.50</td>\n",
       "      <td>10376.47</td>\n",
       "      <td>6910</td>\n",
       "      <td>971</td>\n",
       "      <td>3</td>\n",
       "      <td>3.828221</td>\n",
       "      <td>4.152898</td>\n",
       "      <td>8.462785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>56.83</td>\n",
       "      <td>11789.55</td>\n",
       "      <td>7444</td>\n",
       "      <td>955</td>\n",
       "      <td>4</td>\n",
       "      <td>4.047565</td>\n",
       "      <td>4.398711</td>\n",
       "      <td>8.268432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>935</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>51.87</td>\n",
       "      <td>5398.11</td>\n",
       "      <td>5761</td>\n",
       "      <td>905</td>\n",
       "      <td>4</td>\n",
       "      <td>3.477827</td>\n",
       "      <td>4.120481</td>\n",
       "      <td>7.754680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>936</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>69.10</td>\n",
       "      <td>8248.91</td>\n",
       "      <td>2413</td>\n",
       "      <td>481</td>\n",
       "      <td>4</td>\n",
       "      <td>1.958246</td>\n",
       "      <td>2.881280</td>\n",
       "      <td>8.607197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921</th>\n",
       "      <td>937</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37.98</td>\n",
       "      <td>11005.79</td>\n",
       "      <td>5094</td>\n",
       "      <td>844</td>\n",
       "      <td>2</td>\n",
       "      <td>3.878633</td>\n",
       "      <td>4.731363</td>\n",
       "      <td>6.876775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922</th>\n",
       "      <td>938</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>49.00</td>\n",
       "      <td>10714.29</td>\n",
       "      <td>7341</td>\n",
       "      <td>1034</td>\n",
       "      <td>1</td>\n",
       "      <td>5.702747</td>\n",
       "      <td>6.805263</td>\n",
       "      <td>4.773887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>939</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>45.13</td>\n",
       "      <td>9483.71</td>\n",
       "      <td>5628</td>\n",
       "      <td>845</td>\n",
       "      <td>1</td>\n",
       "      <td>3.549882</td>\n",
       "      <td>4.158287</td>\n",
       "      <td>7.791503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>924 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  liczba pokoi  pow przynależna  pu lokalu  cena mkw  \\\n",
       "0             0             2                1      43.41  10827.00   \n",
       "1             1             1                1      41.57  12244.41   \n",
       "2             2             2                1      56.99  11335.32   \n",
       "3             3             1                0      42.50  10376.47   \n",
       "4             4             2                0      56.83  11789.55   \n",
       "..          ...           ...              ...        ...       ...   \n",
       "919         935             2                1      51.87   5398.11   \n",
       "920         936             3                1      69.10   8248.91   \n",
       "921         937             2                1      37.98  11005.79   \n",
       "922         938             1                0      49.00  10714.29   \n",
       "923         939             2                0      45.13   9483.71   \n",
       "\n",
       "     road_distance  road_time  kondygnacja  odl bagatela  odl dworzec  \\\n",
       "0             5613       1056            2      4.248644     4.369925   \n",
       "1             7479        977            3      4.141580     4.479480   \n",
       "2             5754       1083            3      4.356337     4.443816   \n",
       "3             6910        971            3      3.828221     4.152898   \n",
       "4             7444        955            4      4.047565     4.398711   \n",
       "..             ...        ...          ...           ...          ...   \n",
       "919           5761        905            4      3.477827     4.120481   \n",
       "920           2413        481            4      1.958246     2.881280   \n",
       "921           5094        844            2      3.878633     4.731363   \n",
       "922           7341       1034            1      5.702747     6.805263   \n",
       "923           5628        845            1      3.549882     4.158287   \n",
       "\n",
       "     odl lotnisko  \n",
       "0        8.979016  \n",
       "1        8.267711  \n",
       "2        9.070740  \n",
       "3        8.462785  \n",
       "4        8.268432  \n",
       "..            ...  \n",
       "919      7.754680  \n",
       "920      8.607197  \n",
       "921      6.876775  \n",
       "922      4.773887  \n",
       "923      7.791503  \n",
       "\n",
       "[924 rows x 11 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_excel('D:/real_estate_python/dane_1050_bezOdst.xlsx', sheet_name=0) \n",
    "df1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ca503896",
   "metadata": {},
   "source": [
    "Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "823bab00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df1[['liczba pokoi', 'pow przynależna', 'pu lokalu', 'road_distance', 'road_time', 'kondygnacja', 'odl bagatela',\n",
    "       'odl dworzec', 'odl lotnisko']]\n",
    "y = df1['cena mkw']\n",
    "\n",
    "training_set = X\n",
    "prediction_set = y\n",
    "X_train, X_test, y_train, y_test = train_test_split(training_set, prediction_set, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "36decfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.asarray((X_train.values.tolist()))\n",
    "train_y = np.asarray((y_train.values.tolist()))\n",
    "test_x = np.asarray((X_test.values.tolist()))\n",
    "test_y = np.asarray((y_test.values.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a7ba1374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.86468200e+00 2.66576455e-01 4.95977808e+01 4.45280244e+03\n",
      " 7.63209743e+02 3.32341001e+00 3.06269141e+00 3.37644169e+00\n",
      " 9.16820658e+00]\n",
      "\n",
      "\n",
      "[8.40829058e-01 4.42169027e-01 2.01523152e+01 1.80972340e+03\n",
      " 2.17602226e+02 2.30070443e+00 1.34873065e+00 1.36639817e+00\n",
      " 1.82392632e+00]\n",
      "\n",
      "\n",
      "[[ 2.53953878  1.65869498  2.31001841 ...  1.62160412  1.88924152\n",
      "  -1.63400692]\n",
      " [-1.02836836  1.65869498 -0.84942006 ...  1.12641267  0.15100209\n",
      "   2.11144007]\n",
      " [ 2.53953878  1.65869498  3.37738956 ... -0.43103484 -0.0295632\n",
      "  -0.53722658]\n",
      " ...\n",
      " [-1.02836836 -0.6028836  -1.24838166 ... -1.18080793 -1.40919984\n",
      "   0.63721987]\n",
      " [-1.02836836 -0.6028836  -0.54474043 ...  1.03063704  0.62638744\n",
      "   0.54275077]\n",
      " [-1.02836836 -0.6028836  -0.69509536 ...  1.0595232   0.23224458\n",
      "   1.66648242]]\n"
     ]
    }
   ],
   "source": [
    "train_mean = np.mean(train_x, axis=0)\n",
    "print(train_mean)\n",
    "print(\"\\n\")\n",
    "train_std = np.std(train_x, axis=0)\n",
    "print(train_std)\n",
    "print(\"\\n\")\n",
    "train_x = (train_x - train_mean) / train_std\n",
    "print(train_x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8cc3444b",
   "metadata": {},
   "source": [
    "Modeling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c9105bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = keras.Sequential([\n",
    "        Dense(32, activation=tf.nn.relu, input_shape=[len(train_x[0])]),\n",
    "        Dense(16, activation=tf.nn.relu),\n",
    "        Dense(1),\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=tf.optimizers.Adam(), \n",
    "                  loss='mse',\n",
    "                  metrics=['mae', 'mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "22ed8fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "21/21 [==============================] - 1s 11ms/step - loss: 110860192.0000 - mae: 10337.6660 - mse: 110860192.0000 - val_loss: 114805208.0000 - val_mae: 10562.7500 - val_mse: 114805208.0000\n",
      "Epoch 2/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 110847784.0000 - mae: 10337.0645 - mse: 110847784.0000 - val_loss: 114791352.0000 - val_mae: 10562.0879 - val_mse: 114791352.0000\n",
      "Epoch 3/300\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 110833904.0000 - mae: 10336.3857 - mse: 110833904.0000 - val_loss: 114773928.0000 - val_mae: 10561.2539 - val_mse: 114773928.0000\n",
      "Epoch 4/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 110814240.0000 - mae: 10335.4346 - mse: 110814240.0000 - val_loss: 114747520.0000 - val_mae: 10559.9951 - val_mse: 114747520.0000\n",
      "Epoch 5/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 110784064.0000 - mae: 10333.9668 - mse: 110784064.0000 - val_loss: 114707456.0000 - val_mae: 10558.0879 - val_mse: 114707456.0000\n",
      "Epoch 6/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 110739232.0000 - mae: 10331.7930 - mse: 110739232.0000 - val_loss: 114648992.0000 - val_mae: 10555.3096 - val_mse: 114648992.0000\n",
      "Epoch 7/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 110674264.0000 - mae: 10328.6504 - mse: 110674264.0000 - val_loss: 114567320.0000 - val_mae: 10551.4404 - val_mse: 114567320.0000\n",
      "Epoch 8/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 110584360.0000 - mae: 10324.3232 - mse: 110584360.0000 - val_loss: 114455568.0000 - val_mae: 10546.1436 - val_mse: 114455568.0000\n",
      "Epoch 9/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 110462976.0000 - mae: 10318.4678 - mse: 110462976.0000 - val_loss: 114307672.0000 - val_mae: 10539.1406 - val_mse: 114307672.0000\n",
      "Epoch 10/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 110301968.0000 - mae: 10310.7314 - mse: 110301968.0000 - val_loss: 114117360.0000 - val_mae: 10530.1328 - val_mse: 114117360.0000\n",
      "Epoch 11/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 110098472.0000 - mae: 10300.9316 - mse: 110098472.0000 - val_loss: 113877864.0000 - val_mae: 10518.7939 - val_mse: 113877864.0000\n",
      "Epoch 12/300\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 109844544.0000 - mae: 10288.6348 - mse: 109844544.0000 - val_loss: 113583824.0000 - val_mae: 10504.8711 - val_mse: 113583824.0000\n",
      "Epoch 13/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 109535728.0000 - mae: 10273.8291 - mse: 109535728.0000 - val_loss: 113232104.0000 - val_mae: 10488.1875 - val_mse: 113232104.0000\n",
      "Epoch 14/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 109166688.0000 - mae: 10256.0078 - mse: 109166688.0000 - val_loss: 112811696.0000 - val_mae: 10468.2090 - val_mse: 112811696.0000\n",
      "Epoch 15/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 108724768.0000 - mae: 10234.6953 - mse: 108724768.0000 - val_loss: 112314776.0000 - val_mae: 10444.5693 - val_mse: 112314776.0000\n",
      "Epoch 16/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 108206536.0000 - mae: 10209.4980 - mse: 108206536.0000 - val_loss: 111728432.0000 - val_mae: 10416.6182 - val_mse: 111728432.0000\n",
      "Epoch 17/300\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 107597768.0000 - mae: 10180.1396 - mse: 107597768.0000 - val_loss: 111061008.0000 - val_mae: 10384.6396 - val_mse: 111061008.0000\n",
      "Epoch 18/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 106907288.0000 - mae: 10146.4482 - mse: 106907288.0000 - val_loss: 110297072.0000 - val_mae: 10347.9639 - val_mse: 110297072.0000\n",
      "Epoch 19/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 106123504.0000 - mae: 10108.0361 - mse: 106123504.0000 - val_loss: 109444928.0000 - val_mae: 10306.8848 - val_mse: 109444928.0000\n",
      "Epoch 20/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 105244952.0000 - mae: 10064.9629 - mse: 105244952.0000 - val_loss: 108501008.0000 - val_mae: 10261.0967 - val_mse: 108501008.0000\n",
      "Epoch 21/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 104276840.0000 - mae: 10017.3066 - mse: 104276840.0000 - val_loss: 107455656.0000 - val_mae: 10210.1211 - val_mse: 107455656.0000\n",
      "Epoch 22/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 103209848.0000 - mae: 9964.2861 - mse: 103209848.0000 - val_loss: 106303464.0000 - val_mae: 10153.6904 - val_mse: 106303464.0000\n",
      "Epoch 23/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 102042520.0000 - mae: 9906.0918 - mse: 102042520.0000 - val_loss: 105053560.0000 - val_mae: 10091.9082 - val_mse: 105053560.0000\n",
      "Epoch 24/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 100770040.0000 - mae: 9841.9365 - mse: 100770040.0000 - val_loss: 103708216.0000 - val_mae: 10024.9307 - val_mse: 103708216.0000\n",
      "Epoch 25/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 99400992.0000 - mae: 9772.5312 - mse: 99400992.0000 - val_loss: 102253552.0000 - val_mae: 9951.9258 - val_mse: 102253552.0000\n",
      "Epoch 26/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 97933776.0000 - mae: 9697.2695 - mse: 97933776.0000 - val_loss: 100685920.0000 - val_mae: 9872.5732 - val_mse: 100685920.0000\n",
      "Epoch 27/300\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 96361824.0000 - mae: 9615.9873 - mse: 96361824.0000 - val_loss: 99025232.0000 - val_mae: 9787.6289 - val_mse: 99025232.0000\n",
      "Epoch 28/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 94691224.0000 - mae: 9529.3320 - mse: 94691224.0000 - val_loss: 97280072.0000 - val_mae: 9697.2705 - val_mse: 97280072.0000\n",
      "Epoch 29/300\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 92942392.0000 - mae: 9436.2627 - mse: 92942392.0000 - val_loss: 95415928.0000 - val_mae: 9599.7266 - val_mse: 95415928.0000\n",
      "Epoch 30/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 91075480.0000 - mae: 9337.2227 - mse: 91075480.0000 - val_loss: 93489136.0000 - val_mae: 9497.5176 - val_mse: 93489136.0000\n",
      "Epoch 31/300\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 89146832.0000 - mae: 9232.6660 - mse: 89146832.0000 - val_loss: 91446096.0000 - val_mae: 9387.8018 - val_mse: 91446096.0000\n",
      "Epoch 32/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 87112192.0000 - mae: 9121.0996 - mse: 87112192.0000 - val_loss: 89341976.0000 - val_mae: 9273.0371 - val_mse: 89341976.0000\n",
      "Epoch 33/300\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 85010648.0000 - mae: 9004.1465 - mse: 85010648.0000 - val_loss: 87159952.0000 - val_mae: 9152.0986 - val_mse: 87159952.0000\n",
      "Epoch 34/300\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 82829976.0000 - mae: 8880.8564 - mse: 82829976.0000 - val_loss: 84905016.0000 - val_mae: 9025.0557 - val_mse: 84905016.0000\n",
      "Epoch 35/300\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 80591376.0000 - mae: 8750.7725 - mse: 80591376.0000 - val_loss: 82577248.0000 - val_mae: 8891.6338 - val_mse: 82577248.0000\n",
      "Epoch 36/300\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 78284560.0000 - mae: 8615.3936 - mse: 78284560.0000 - val_loss: 80204024.0000 - val_mae: 8752.9805 - val_mse: 80204024.0000\n",
      "Epoch 37/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 75940336.0000 - mae: 8475.2002 - mse: 75940336.0000 - val_loss: 77765984.0000 - val_mae: 8606.9844 - val_mse: 77765984.0000\n",
      "Epoch 38/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 73545768.0000 - mae: 8328.1787 - mse: 73545768.0000 - val_loss: 75290904.0000 - val_mae: 8456.2832 - val_mse: 75290904.0000\n",
      "Epoch 39/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 71108552.0000 - mae: 8177.2729 - mse: 71108552.0000 - val_loss: 72808272.0000 - val_mae: 8301.4971 - val_mse: 72808272.0000\n",
      "Epoch 40/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 68659944.0000 - mae: 8019.9731 - mse: 68659944.0000 - val_loss: 70294680.0000 - val_mae: 8141.0430 - val_mse: 70294680.0000\n",
      "Epoch 41/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 66192184.0000 - mae: 7859.8931 - mse: 66192184.0000 - val_loss: 67777856.0000 - val_mae: 7975.9595 - val_mse: 67777856.0000\n",
      "Epoch 42/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 63722852.0000 - mae: 7695.2021 - mse: 63722852.0000 - val_loss: 65242124.0000 - val_mae: 7805.7544 - val_mse: 65242124.0000\n",
      "Epoch 43/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 61249072.0000 - mae: 7525.4497 - mse: 61249072.0000 - val_loss: 62722372.0000 - val_mae: 7631.7930 - val_mse: 62722372.0000\n",
      "Epoch 44/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 58780684.0000 - mae: 7355.5347 - mse: 58780684.0000 - val_loss: 60235604.0000 - val_mae: 7454.2422 - val_mse: 60235604.0000\n",
      "Epoch 45/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 56346528.0000 - mae: 7181.4346 - mse: 56346528.0000 - val_loss: 57747536.0000 - val_mae: 7271.7954 - val_mse: 57747536.0000\n",
      "Epoch 46/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 53934032.0000 - mae: 7002.1655 - mse: 53934032.0000 - val_loss: 55305808.0000 - val_mae: 7087.1724 - val_mse: 55305808.0000\n",
      "Epoch 47/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 51561688.0000 - mae: 6824.7925 - mse: 51561688.0000 - val_loss: 52928924.0000 - val_mae: 6902.7964 - val_mse: 52928924.0000\n",
      "Epoch 48/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 49248368.0000 - mae: 6646.7720 - mse: 49248368.0000 - val_loss: 50592784.0000 - val_mae: 6736.4922 - val_mse: 50592784.0000\n",
      "Epoch 49/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 46988292.0000 - mae: 6468.1465 - mse: 46988292.0000 - val_loss: 48299844.0000 - val_mae: 6579.3838 - val_mse: 48299844.0000\n",
      "Epoch 50/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 44785520.0000 - mae: 6292.9854 - mse: 44785520.0000 - val_loss: 46087068.0000 - val_mae: 6421.8496 - val_mse: 46087068.0000\n",
      "Epoch 51/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 42653560.0000 - mae: 6120.9258 - mse: 42653560.0000 - val_loss: 43965328.0000 - val_mae: 6264.1797 - val_mse: 43965328.0000\n",
      "Epoch 52/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 40609116.0000 - mae: 5948.7114 - mse: 40609116.0000 - val_loss: 41894788.0000 - val_mae: 6103.6206 - val_mse: 41894788.0000\n",
      "Epoch 53/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 38642432.0000 - mae: 5780.3320 - mse: 38642432.0000 - val_loss: 39915748.0000 - val_mae: 5943.0786 - val_mse: 39915748.0000\n",
      "Epoch 54/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 36761928.0000 - mae: 5616.1152 - mse: 36761928.0000 - val_loss: 38019824.0000 - val_mae: 5781.7734 - val_mse: 38019824.0000\n",
      "Epoch 55/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 34969384.0000 - mae: 5456.8257 - mse: 34969384.0000 - val_loss: 36232012.0000 - val_mae: 5626.8091 - val_mse: 36232012.0000\n",
      "Epoch 56/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 33274100.0000 - mae: 5303.2910 - mse: 33274100.0000 - val_loss: 34536288.0000 - val_mae: 5485.5444 - val_mse: 34536288.0000\n",
      "Epoch 57/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 31679012.0000 - mae: 5156.2109 - mse: 31679012.0000 - val_loss: 32933746.0000 - val_mae: 5344.5088 - val_mse: 32933746.0000\n",
      "Epoch 58/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 30161596.0000 - mae: 5008.2163 - mse: 30161596.0000 - val_loss: 31432078.0000 - val_mae: 5204.9863 - val_mse: 31432078.0000\n",
      "Epoch 59/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 28775204.0000 - mae: 4870.0449 - mse: 28775204.0000 - val_loss: 29993184.0000 - val_mae: 5064.2139 - val_mse: 29993184.0000\n",
      "Epoch 60/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 27440792.0000 - mae: 4736.3027 - mse: 27440792.0000 - val_loss: 28676508.0000 - val_mae: 4927.3770 - val_mse: 28676508.0000\n",
      "Epoch 61/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 26215130.0000 - mae: 4604.0430 - mse: 26215130.0000 - val_loss: 27469576.0000 - val_mae: 4795.2114 - val_mse: 27469576.0000\n",
      "Epoch 62/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 25096942.0000 - mae: 4485.8320 - mse: 25096942.0000 - val_loss: 26317886.0000 - val_mae: 4661.3877 - val_mse: 26317886.0000\n",
      "Epoch 63/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 24037816.0000 - mae: 4366.8789 - mse: 24037816.0000 - val_loss: 25274440.0000 - val_mae: 4538.4897 - val_mse: 25274440.0000\n",
      "Epoch 64/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 23076164.0000 - mae: 4259.7686 - mse: 23076164.0000 - val_loss: 24309820.0000 - val_mae: 4421.1240 - val_mse: 24309820.0000\n",
      "Epoch 65/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 22195430.0000 - mae: 4156.9512 - mse: 22195430.0000 - val_loss: 23400980.0000 - val_mae: 4312.6587 - val_mse: 23400980.0000\n",
      "Epoch 66/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 21374814.0000 - mae: 4061.8113 - mse: 21374814.0000 - val_loss: 22574876.0000 - val_mae: 4211.3257 - val_mse: 22574876.0000\n",
      "Epoch 67/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 20624770.0000 - mae: 3975.3657 - mse: 20624770.0000 - val_loss: 21831898.0000 - val_mae: 4114.4707 - val_mse: 21831898.0000\n",
      "Epoch 68/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 19951752.0000 - mae: 3892.9895 - mse: 19951752.0000 - val_loss: 21118694.0000 - val_mae: 4016.9526 - val_mse: 21118694.0000\n",
      "Epoch 69/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 19322002.0000 - mae: 3813.8142 - mse: 19322002.0000 - val_loss: 20494356.0000 - val_mae: 3928.6516 - val_mse: 20494356.0000\n",
      "Epoch 70/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18775742.0000 - mae: 3742.1016 - mse: 18775742.0000 - val_loss: 19898392.0000 - val_mae: 3842.9866 - val_mse: 19898392.0000\n",
      "Epoch 71/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18253024.0000 - mae: 3668.8774 - mse: 18253024.0000 - val_loss: 19360384.0000 - val_mae: 3768.1851 - val_mse: 19360384.0000\n",
      "Epoch 72/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 17782066.0000 - mae: 3606.5605 - mse: 17782066.0000 - val_loss: 18880152.0000 - val_mae: 3698.2461 - val_mse: 18880152.0000\n",
      "Epoch 73/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 17355318.0000 - mae: 3548.1130 - mse: 17355318.0000 - val_loss: 18436042.0000 - val_mae: 3633.0989 - val_mse: 18436042.0000\n",
      "Epoch 74/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16973428.0000 - mae: 3492.9253 - mse: 16973428.0000 - val_loss: 18016518.0000 - val_mae: 3568.9456 - val_mse: 18016518.0000\n",
      "Epoch 75/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16605065.0000 - mae: 3439.6052 - mse: 16605065.0000 - val_loss: 17640054.0000 - val_mae: 3514.9861 - val_mse: 17640054.0000\n",
      "Epoch 76/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 16284820.0000 - mae: 3393.3691 - mse: 16284820.0000 - val_loss: 17278628.0000 - val_mae: 3462.5127 - val_mse: 17278628.0000\n",
      "Epoch 77/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 15969765.0000 - mae: 3346.7019 - mse: 15969765.0000 - val_loss: 16952410.0000 - val_mae: 3414.4255 - val_mse: 16952410.0000\n",
      "Epoch 78/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 15692837.0000 - mae: 3307.8511 - mse: 15692837.0000 - val_loss: 16624401.0000 - val_mae: 3368.6831 - val_mse: 16624401.0000\n",
      "Epoch 79/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 15424615.0000 - mae: 3270.1895 - mse: 15424615.0000 - val_loss: 16343327.0000 - val_mae: 3331.4448 - val_mse: 16343327.0000\n",
      "Epoch 80/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 15187104.0000 - mae: 3234.2292 - mse: 15187104.0000 - val_loss: 16064524.0000 - val_mae: 3294.9041 - val_mse: 16064524.0000\n",
      "Epoch 81/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 14953751.0000 - mae: 3201.0200 - mse: 14953751.0000 - val_loss: 15798153.0000 - val_mae: 3259.1465 - val_mse: 15798153.0000\n",
      "Epoch 82/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14733581.0000 - mae: 3170.7627 - mse: 14733581.0000 - val_loss: 15552661.0000 - val_mae: 3226.3325 - val_mse: 15552661.0000\n",
      "Epoch 83/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14530959.0000 - mae: 3141.2764 - mse: 14530959.0000 - val_loss: 15320348.0000 - val_mae: 3193.2241 - val_mse: 15320348.0000\n",
      "Epoch 84/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 14334533.0000 - mae: 3113.4863 - mse: 14334533.0000 - val_loss: 15095798.0000 - val_mae: 3161.3882 - val_mse: 15095798.0000\n",
      "Epoch 85/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 14142382.0000 - mae: 3087.9468 - mse: 14142382.0000 - val_loss: 14871338.0000 - val_mae: 3133.6584 - val_mse: 14871338.0000\n",
      "Epoch 86/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 13963110.0000 - mae: 3065.4963 - mse: 13963110.0000 - val_loss: 14664484.0000 - val_mae: 3105.4790 - val_mse: 14664484.0000\n",
      "Epoch 87/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 13793613.0000 - mae: 3041.5969 - mse: 13793613.0000 - val_loss: 14455634.0000 - val_mae: 3078.5591 - val_mse: 14455634.0000\n",
      "Epoch 88/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 13620019.0000 - mae: 3018.2256 - mse: 13620019.0000 - val_loss: 14269089.0000 - val_mae: 3055.3169 - val_mse: 14269089.0000\n",
      "Epoch 89/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 13462988.0000 - mae: 2998.6597 - mse: 13462988.0000 - val_loss: 14073014.0000 - val_mae: 3030.9485 - val_mse: 14073014.0000\n",
      "Epoch 90/300\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 13302789.0000 - mae: 2976.2505 - mse: 13302789.0000 - val_loss: 13888639.0000 - val_mae: 3007.5815 - val_mse: 13888639.0000\n",
      "Epoch 91/300\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 13146087.0000 - mae: 2955.8337 - mse: 13146087.0000 - val_loss: 13712479.0000 - val_mae: 2984.8555 - val_mse: 13712479.0000\n",
      "Epoch 92/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 13000729.0000 - mae: 2936.0576 - mse: 13000729.0000 - val_loss: 13520336.0000 - val_mae: 2961.7222 - val_mse: 13520336.0000\n",
      "Epoch 93/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 12848883.0000 - mae: 2915.1892 - mse: 12848883.0000 - val_loss: 13360095.0000 - val_mae: 2940.6033 - val_mse: 13360095.0000\n",
      "Epoch 94/300\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 12705398.0000 - mae: 2894.4082 - mse: 12705398.0000 - val_loss: 13193162.0000 - val_mae: 2918.5352 - val_mse: 13193162.0000\n",
      "Epoch 95/300\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 12572266.0000 - mae: 2874.9788 - mse: 12572266.0000 - val_loss: 13035933.0000 - val_mae: 2895.9900 - val_mse: 13035933.0000\n",
      "Epoch 96/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 12425901.0000 - mae: 2855.4431 - mse: 12425901.0000 - val_loss: 12864504.0000 - val_mae: 2875.1406 - val_mse: 12864504.0000\n",
      "Epoch 97/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 12291639.0000 - mae: 2838.3723 - mse: 12291639.0000 - val_loss: 12702071.0000 - val_mae: 2855.4587 - val_mse: 12702071.0000\n",
      "Epoch 98/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 12157803.0000 - mae: 2818.8960 - mse: 12157803.0000 - val_loss: 12554818.0000 - val_mae: 2832.0430 - val_mse: 12554818.0000\n",
      "Epoch 99/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 12024081.0000 - mae: 2800.5701 - mse: 12024081.0000 - val_loss: 12397026.0000 - val_mae: 2812.8555 - val_mse: 12397026.0000\n",
      "Epoch 100/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 11893380.0000 - mae: 2783.1082 - mse: 11893380.0000 - val_loss: 12248061.0000 - val_mae: 2792.6985 - val_mse: 12248061.0000\n",
      "Epoch 101/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 11768226.0000 - mae: 2764.6602 - mse: 11768226.0000 - val_loss: 12105497.0000 - val_mae: 2770.2319 - val_mse: 12105497.0000\n",
      "Epoch 102/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 11640440.0000 - mae: 2747.1814 - mse: 11640440.0000 - val_loss: 11957701.0000 - val_mae: 2750.3923 - val_mse: 11957701.0000\n",
      "Epoch 103/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 11521549.0000 - mae: 2730.7131 - mse: 11521549.0000 - val_loss: 11805237.0000 - val_mae: 2729.2092 - val_mse: 11805237.0000\n",
      "Epoch 104/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 11398422.0000 - mae: 2712.8489 - mse: 11398422.0000 - val_loss: 11661776.0000 - val_mae: 2710.7529 - val_mse: 11661776.0000\n",
      "Epoch 105/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 11276409.0000 - mae: 2696.2139 - mse: 11276409.0000 - val_loss: 11522394.0000 - val_mae: 2691.5710 - val_mse: 11522394.0000\n",
      "Epoch 106/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 11164839.0000 - mae: 2678.1951 - mse: 11164839.0000 - val_loss: 11391357.0000 - val_mae: 2671.5540 - val_mse: 11391357.0000\n",
      "Epoch 107/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 11040442.0000 - mae: 2660.9641 - mse: 11040442.0000 - val_loss: 11256861.0000 - val_mae: 2653.4377 - val_mse: 11256861.0000\n",
      "Epoch 108/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 10929269.0000 - mae: 2645.2930 - mse: 10929269.0000 - val_loss: 11117387.0000 - val_mae: 2634.5144 - val_mse: 11117387.0000\n",
      "Epoch 109/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 10814279.0000 - mae: 2628.8413 - mse: 10814279.0000 - val_loss: 10991347.0000 - val_mae: 2615.8118 - val_mse: 10991347.0000\n",
      "Epoch 110/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 10700947.0000 - mae: 2610.7849 - mse: 10700947.0000 - val_loss: 10870344.0000 - val_mae: 2596.9714 - val_mse: 10870344.0000\n",
      "Epoch 111/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 10592305.0000 - mae: 2594.1794 - mse: 10592305.0000 - val_loss: 10741009.0000 - val_mae: 2579.5989 - val_mse: 10741009.0000\n",
      "Epoch 112/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 10483854.0000 - mae: 2578.9026 - mse: 10483854.0000 - val_loss: 10609008.0000 - val_mae: 2561.6125 - val_mse: 10609008.0000\n",
      "Epoch 113/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 10374056.0000 - mae: 2562.7290 - mse: 10374056.0000 - val_loss: 10481596.0000 - val_mae: 2544.4204 - val_mse: 10481596.0000\n",
      "Epoch 114/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10270614.0000 - mae: 2548.1516 - mse: 10270614.0000 - val_loss: 10355323.0000 - val_mae: 2528.1528 - val_mse: 10355323.0000\n",
      "Epoch 115/300\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 10166074.0000 - mae: 2532.4302 - mse: 10166074.0000 - val_loss: 10238422.0000 - val_mae: 2510.0164 - val_mse: 10238422.0000\n",
      "Epoch 116/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10062077.0000 - mae: 2517.3071 - mse: 10062077.0000 - val_loss: 10122295.0000 - val_mae: 2495.0481 - val_mse: 10122295.0000\n",
      "Epoch 117/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9961101.0000 - mae: 2503.9800 - mse: 9961101.0000 - val_loss: 10000244.0000 - val_mae: 2479.5925 - val_mse: 10000244.0000\n",
      "Epoch 118/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 9858259.0000 - mae: 2487.8730 - mse: 9858259.0000 - val_loss: 9888623.0000 - val_mae: 2463.0757 - val_mse: 9888622.0000\n",
      "Epoch 119/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 9761580.0000 - mae: 2473.0886 - mse: 9761580.0000 - val_loss: 9773326.0000 - val_mae: 2447.2847 - val_mse: 9773326.0000\n",
      "Epoch 120/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 9665921.0000 - mae: 2459.6294 - mse: 9665921.0000 - val_loss: 9664088.0000 - val_mae: 2433.5959 - val_mse: 9664088.0000\n",
      "Epoch 121/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9567910.0000 - mae: 2444.6621 - mse: 9567910.0000 - val_loss: 9554608.0000 - val_mae: 2418.0791 - val_mse: 9554608.0000\n",
      "Epoch 122/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9470890.0000 - mae: 2428.9045 - mse: 9470890.0000 - val_loss: 9454452.0000 - val_mae: 2401.9944 - val_mse: 9454452.0000\n",
      "Epoch 123/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 9379391.0000 - mae: 2412.8394 - mse: 9379391.0000 - val_loss: 9352054.0000 - val_mae: 2387.0198 - val_mse: 9352054.0000\n",
      "Epoch 124/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 9286275.0000 - mae: 2400.0862 - mse: 9286275.0000 - val_loss: 9242049.0000 - val_mae: 2373.5522 - val_mse: 9242049.0000\n",
      "Epoch 125/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 9193303.0000 - mae: 2386.3577 - mse: 9193303.0000 - val_loss: 9138009.0000 - val_mae: 2358.6465 - val_mse: 9138009.0000\n",
      "Epoch 126/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 9105932.0000 - mae: 2373.7153 - mse: 9105932.0000 - val_loss: 9033240.0000 - val_mae: 2344.7915 - val_mse: 9033240.0000\n",
      "Epoch 127/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 9013551.0000 - mae: 2359.1260 - mse: 9013551.0000 - val_loss: 8940838.0000 - val_mae: 2330.0107 - val_mse: 8940838.0000\n",
      "Epoch 128/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 8930870.0000 - mae: 2344.4868 - mse: 8930870.0000 - val_loss: 8842051.0000 - val_mae: 2314.4753 - val_mse: 8842051.0000\n",
      "Epoch 129/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 8842210.0000 - mae: 2331.2014 - mse: 8842210.0000 - val_loss: 8747864.0000 - val_mae: 2300.1338 - val_mse: 8747864.0000\n",
      "Epoch 130/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 8759806.0000 - mae: 2319.0586 - mse: 8759806.0000 - val_loss: 8659129.0000 - val_mae: 2287.6873 - val_mse: 8659129.0000\n",
      "Epoch 131/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8676397.0000 - mae: 2306.4663 - mse: 8676397.0000 - val_loss: 8565519.0000 - val_mae: 2273.9395 - val_mse: 8565519.0000\n",
      "Epoch 132/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8596291.0000 - mae: 2293.1677 - mse: 8596291.0000 - val_loss: 8473591.0000 - val_mae: 2258.4456 - val_mse: 8473591.0000\n",
      "Epoch 133/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8515481.0000 - mae: 2281.9741 - mse: 8515481.0000 - val_loss: 8379347.0000 - val_mae: 2246.8115 - val_mse: 8379347.0000\n",
      "Epoch 134/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 8436493.0000 - mae: 2268.3303 - mse: 8436493.0000 - val_loss: 8292723.0000 - val_mae: 2231.7659 - val_mse: 8292723.0000\n",
      "Epoch 135/300\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8357296.5000 - mae: 2255.8035 - mse: 8357296.5000 - val_loss: 8204897.0000 - val_mae: 2217.1934 - val_mse: 8204897.0000\n",
      "Epoch 136/300\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8275979.0000 - mae: 2243.3657 - mse: 8275979.0000 - val_loss: 8115847.0000 - val_mae: 2203.9182 - val_mse: 8115847.0000\n",
      "Epoch 137/300\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8200484.0000 - mae: 2232.0208 - mse: 8200484.0000 - val_loss: 8029973.0000 - val_mae: 2190.5259 - val_mse: 8029973.0000\n",
      "Epoch 138/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8123235.5000 - mae: 2220.7812 - mse: 8123235.5000 - val_loss: 7945527.5000 - val_mae: 2177.9028 - val_mse: 7945527.5000\n",
      "Epoch 139/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8049788.0000 - mae: 2210.0034 - mse: 8049788.0000 - val_loss: 7862590.5000 - val_mae: 2165.3638 - val_mse: 7862590.5000\n",
      "Epoch 140/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 7977154.0000 - mae: 2198.4561 - mse: 7977154.0000 - val_loss: 7778107.0000 - val_mae: 2150.5325 - val_mse: 7778107.0000\n",
      "Epoch 141/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 7904849.0000 - mae: 2187.4062 - mse: 7904849.0000 - val_loss: 7697134.5000 - val_mae: 2137.7190 - val_mse: 7697134.5000\n",
      "Epoch 142/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 7832388.0000 - mae: 2175.8254 - mse: 7832388.0000 - val_loss: 7610175.0000 - val_mae: 2123.1794 - val_mse: 7610175.0000\n",
      "Epoch 143/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 7763165.0000 - mae: 2163.3057 - mse: 7763165.0000 - val_loss: 7553879.5000 - val_mae: 2110.3350 - val_mse: 7553879.5000\n",
      "Epoch 144/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 7692396.0000 - mae: 2151.3503 - mse: 7692396.0000 - val_loss: 7468936.0000 - val_mae: 2095.9814 - val_mse: 7468936.0000\n",
      "Epoch 145/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 7623481.5000 - mae: 2141.7468 - mse: 7623481.5000 - val_loss: 7383528.0000 - val_mae: 2083.2048 - val_mse: 7383528.0000\n",
      "Epoch 146/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 7553775.5000 - mae: 2130.3093 - mse: 7553775.5000 - val_loss: 7318833.5000 - val_mae: 2071.0132 - val_mse: 7318833.5000\n",
      "Epoch 147/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 7488100.0000 - mae: 2120.2129 - mse: 7488100.0000 - val_loss: 7244531.5000 - val_mae: 2057.9773 - val_mse: 7244531.5000\n",
      "Epoch 148/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7426591.5000 - mae: 2110.3337 - mse: 7426591.5000 - val_loss: 7166808.0000 - val_mae: 2045.5171 - val_mse: 7166808.0000\n",
      "Epoch 149/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 7359935.5000 - mae: 2099.5637 - mse: 7359935.5000 - val_loss: 7099491.0000 - val_mae: 2032.4135 - val_mse: 7099491.0000\n",
      "Epoch 150/300\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7295530.5000 - mae: 2088.9058 - mse: 7295530.5000 - val_loss: 7038667.0000 - val_mae: 2021.4167 - val_mse: 7038667.0000\n",
      "Epoch 151/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 7234759.5000 - mae: 2078.7588 - mse: 7234759.5000 - val_loss: 6970213.5000 - val_mae: 2008.6910 - val_mse: 6970213.5000\n",
      "Epoch 152/300\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7175830.0000 - mae: 2068.6555 - mse: 7175830.0000 - val_loss: 6904678.5000 - val_mae: 1995.5063 - val_mse: 6904678.5000\n",
      "Epoch 153/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 7115879.0000 - mae: 2059.1711 - mse: 7115879.0000 - val_loss: 6841323.0000 - val_mae: 1984.8661 - val_mse: 6841323.0000\n",
      "Epoch 154/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7057749.0000 - mae: 2049.8562 - mse: 7057749.0000 - val_loss: 6774443.0000 - val_mae: 1975.0636 - val_mse: 6774443.0000\n",
      "Epoch 155/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6999656.0000 - mae: 2040.9077 - mse: 6999656.0000 - val_loss: 6706807.5000 - val_mae: 1962.6615 - val_mse: 6706807.5000\n",
      "Epoch 156/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 6942259.0000 - mae: 2030.9795 - mse: 6942259.0000 - val_loss: 6652129.5000 - val_mae: 1951.8831 - val_mse: 6652129.5000\n",
      "Epoch 157/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6887896.0000 - mae: 2022.5596 - mse: 6887896.0000 - val_loss: 6583544.5000 - val_mae: 1942.1375 - val_mse: 6583544.5000\n",
      "Epoch 158/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 6835631.0000 - mae: 2013.3405 - mse: 6835631.0000 - val_loss: 6529456.5000 - val_mae: 1931.0524 - val_mse: 6529456.5000\n",
      "Epoch 159/300\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6778891.5000 - mae: 2003.6918 - mse: 6778891.5000 - val_loss: 6468219.5000 - val_mae: 1921.6016 - val_mse: 6468219.5000\n",
      "Epoch 160/300\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6729009.5000 - mae: 1996.4181 - mse: 6729009.5000 - val_loss: 6403706.5000 - val_mae: 1911.2029 - val_mse: 6403706.5000\n",
      "Epoch 161/300\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6673071.0000 - mae: 1986.3671 - mse: 6673071.0000 - val_loss: 6354967.5000 - val_mae: 1900.4991 - val_mse: 6354967.5000\n",
      "Epoch 162/300\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6621370.5000 - mae: 1977.7242 - mse: 6621370.5000 - val_loss: 6301678.5000 - val_mae: 1891.1444 - val_mse: 6301678.5000\n",
      "Epoch 163/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6572572.5000 - mae: 1969.1946 - mse: 6572572.5000 - val_loss: 6248839.5000 - val_mae: 1881.7411 - val_mse: 6248839.5000\n",
      "Epoch 164/300\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6522884.5000 - mae: 1961.4053 - mse: 6522884.5000 - val_loss: 6188411.5000 - val_mae: 1870.6757 - val_mse: 6188411.5000\n",
      "Epoch 165/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6471659.0000 - mae: 1953.5562 - mse: 6471659.0000 - val_loss: 6138050.0000 - val_mae: 1862.7925 - val_mse: 6138050.0000\n",
      "Epoch 166/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6423750.0000 - mae: 1945.1995 - mse: 6423750.0000 - val_loss: 6087461.5000 - val_mae: 1853.2338 - val_mse: 6087461.5000\n",
      "Epoch 167/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 6376614.5000 - mae: 1937.4197 - mse: 6376614.5000 - val_loss: 6032331.0000 - val_mae: 1844.4343 - val_mse: 6032331.0000\n",
      "Epoch 168/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 6334698.0000 - mae: 1929.7792 - mse: 6334698.0000 - val_loss: 5991849.0000 - val_mae: 1833.7285 - val_mse: 5991849.0000\n",
      "Epoch 169/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6284770.5000 - mae: 1922.0328 - mse: 6284770.5000 - val_loss: 5939405.5000 - val_mae: 1828.0015 - val_mse: 5939405.5000\n",
      "Epoch 170/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 6238905.5000 - mae: 1915.7151 - mse: 6238905.5000 - val_loss: 5891740.5000 - val_mae: 1819.7728 - val_mse: 5891740.5000\n",
      "Epoch 171/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 6195831.5000 - mae: 1908.9927 - mse: 6195831.5000 - val_loss: 5837710.5000 - val_mae: 1811.9198 - val_mse: 5837710.5000\n",
      "Epoch 172/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 6151242.0000 - mae: 1902.0157 - mse: 6151242.0000 - val_loss: 5789046.5000 - val_mae: 1802.9031 - val_mse: 5789046.5000\n",
      "Epoch 173/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 6111470.0000 - mae: 1896.0079 - mse: 6111470.0000 - val_loss: 5743387.0000 - val_mae: 1795.6404 - val_mse: 5743387.0000\n",
      "Epoch 174/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 6066459.5000 - mae: 1888.3071 - mse: 6066459.5000 - val_loss: 5701969.5000 - val_mae: 1788.8357 - val_mse: 5701969.5000\n",
      "Epoch 175/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 6025544.0000 - mae: 1881.8357 - mse: 6025544.0000 - val_loss: 5652278.5000 - val_mae: 1779.7292 - val_mse: 5652278.5000\n",
      "Epoch 176/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 5983869.0000 - mae: 1874.8218 - mse: 5983869.0000 - val_loss: 5611409.5000 - val_mae: 1770.0872 - val_mse: 5611409.5000\n",
      "Epoch 177/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 5944297.5000 - mae: 1868.5007 - mse: 5944297.5000 - val_loss: 5567238.5000 - val_mae: 1764.6617 - val_mse: 5567238.5000\n",
      "Epoch 178/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5904168.5000 - mae: 1861.2872 - mse: 5904168.5000 - val_loss: 5532196.0000 - val_mae: 1756.8473 - val_mse: 5532196.0000\n",
      "Epoch 179/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 5863558.0000 - mae: 1855.3152 - mse: 5863558.0000 - val_loss: 5498163.0000 - val_mae: 1752.7903 - val_mse: 5498163.0000\n",
      "Epoch 180/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 5827640.0000 - mae: 1849.6075 - mse: 5827640.0000 - val_loss: 5443032.5000 - val_mae: 1745.3383 - val_mse: 5443032.5000\n",
      "Epoch 181/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 5787244.5000 - mae: 1843.6080 - mse: 5787244.5000 - val_loss: 5403607.5000 - val_mae: 1740.2551 - val_mse: 5403607.5000\n",
      "Epoch 182/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 5748725.0000 - mae: 1837.7722 - mse: 5748725.0000 - val_loss: 5365062.0000 - val_mae: 1733.6537 - val_mse: 5365062.0000\n",
      "Epoch 183/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 5714144.5000 - mae: 1832.0481 - mse: 5714144.5000 - val_loss: 5326832.5000 - val_mae: 1728.4918 - val_mse: 5326832.5000\n",
      "Epoch 184/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 5678129.5000 - mae: 1826.1169 - mse: 5678129.5000 - val_loss: 5287000.0000 - val_mae: 1722.1293 - val_mse: 5287000.0000\n",
      "Epoch 185/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 5641791.0000 - mae: 1820.5680 - mse: 5641791.0000 - val_loss: 5249298.0000 - val_mae: 1717.2911 - val_mse: 5249297.5000\n",
      "Epoch 186/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5611803.5000 - mae: 1816.1755 - mse: 5611803.5000 - val_loss: 5205659.5000 - val_mae: 1711.6733 - val_mse: 5205660.0000\n",
      "Epoch 187/300\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 5578385.0000 - mae: 1810.4199 - mse: 5578385.0000 - val_loss: 5185446.5000 - val_mae: 1707.3035 - val_mse: 5185446.5000\n",
      "Epoch 188/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 5540275.0000 - mae: 1804.4177 - mse: 5540275.0000 - val_loss: 5148137.5000 - val_mae: 1702.5685 - val_mse: 5148137.0000\n",
      "Epoch 189/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 5510247.0000 - mae: 1800.4680 - mse: 5510247.0000 - val_loss: 5106936.0000 - val_mae: 1698.1292 - val_mse: 5106936.0000\n",
      "Epoch 190/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 5475613.5000 - mae: 1794.3495 - mse: 5475613.5000 - val_loss: 5082596.0000 - val_mae: 1692.7629 - val_mse: 5082596.0000\n",
      "Epoch 191/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 5443673.5000 - mae: 1789.7241 - mse: 5443673.5000 - val_loss: 5042984.0000 - val_mae: 1689.0315 - val_mse: 5042984.0000\n",
      "Epoch 192/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 5414402.5000 - mae: 1785.1660 - mse: 5414402.5000 - val_loss: 4999562.0000 - val_mae: 1683.6279 - val_mse: 4999562.0000\n",
      "Epoch 193/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 5380057.5000 - mae: 1779.7681 - mse: 5380057.5000 - val_loss: 4971030.5000 - val_mae: 1680.3348 - val_mse: 4971030.5000\n",
      "Epoch 194/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 5349471.0000 - mae: 1774.7870 - mse: 5349471.0000 - val_loss: 4942645.0000 - val_mae: 1675.8727 - val_mse: 4942645.0000\n",
      "Epoch 195/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5321807.0000 - mae: 1770.3085 - mse: 5321807.0000 - val_loss: 4913390.0000 - val_mae: 1673.4342 - val_mse: 4913390.0000\n",
      "Epoch 196/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 5291462.0000 - mae: 1765.2208 - mse: 5291462.0000 - val_loss: 4881703.0000 - val_mae: 1668.9958 - val_mse: 4881703.0000\n",
      "Epoch 197/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 5262696.0000 - mae: 1760.4940 - mse: 5262696.0000 - val_loss: 4855582.0000 - val_mae: 1664.1965 - val_mse: 4855582.0000\n",
      "Epoch 198/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 5234183.5000 - mae: 1755.8942 - mse: 5234183.5000 - val_loss: 4827071.0000 - val_mae: 1662.0476 - val_mse: 4827071.0000\n",
      "Epoch 199/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 5205995.0000 - mae: 1751.4119 - mse: 5205995.0000 - val_loss: 4800711.0000 - val_mae: 1657.6145 - val_mse: 4800711.0000\n",
      "Epoch 200/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 5178927.5000 - mae: 1747.2590 - mse: 5178927.5000 - val_loss: 4761640.0000 - val_mae: 1653.0353 - val_mse: 4761640.0000\n",
      "Epoch 201/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 5150954.0000 - mae: 1742.5017 - mse: 5150954.0000 - val_loss: 4732628.5000 - val_mae: 1648.6202 - val_mse: 4732628.5000\n",
      "Epoch 202/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 5124978.0000 - mae: 1738.5239 - mse: 5124978.0000 - val_loss: 4710477.0000 - val_mae: 1645.7832 - val_mse: 4710477.0000\n",
      "Epoch 203/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5097852.5000 - mae: 1733.9073 - mse: 5097852.5000 - val_loss: 4684757.5000 - val_mae: 1642.2853 - val_mse: 4684757.5000\n",
      "Epoch 204/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5072598.5000 - mae: 1729.6285 - mse: 5072598.5000 - val_loss: 4647343.5000 - val_mae: 1635.9910 - val_mse: 4647343.5000\n",
      "Epoch 205/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5050082.0000 - mae: 1725.5773 - mse: 5050082.0000 - val_loss: 4621277.5000 - val_mae: 1630.3824 - val_mse: 4621277.5000\n",
      "Epoch 206/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 5022125.5000 - mae: 1720.7473 - mse: 5022125.5000 - val_loss: 4598513.5000 - val_mae: 1627.4138 - val_mse: 4598513.5000\n",
      "Epoch 207/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4996906.0000 - mae: 1717.1017 - mse: 4996906.0000 - val_loss: 4569542.0000 - val_mae: 1624.4210 - val_mse: 4569542.0000\n",
      "Epoch 208/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4974029.0000 - mae: 1713.5876 - mse: 4974029.0000 - val_loss: 4551503.5000 - val_mae: 1622.2114 - val_mse: 4551503.5000\n",
      "Epoch 209/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4949024.0000 - mae: 1709.2034 - mse: 4949024.0000 - val_loss: 4526573.0000 - val_mae: 1617.7451 - val_mse: 4526573.0000\n",
      "Epoch 210/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4926146.0000 - mae: 1705.2086 - mse: 4926146.0000 - val_loss: 4494712.0000 - val_mae: 1612.3284 - val_mse: 4494712.0000\n",
      "Epoch 211/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4902907.5000 - mae: 1701.5002 - mse: 4902907.5000 - val_loss: 4489821.0000 - val_mae: 1611.5192 - val_mse: 4489821.0000\n",
      "Epoch 212/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4877579.5000 - mae: 1697.0731 - mse: 4877579.5000 - val_loss: 4451793.5000 - val_mae: 1605.8040 - val_mse: 4451793.5000\n",
      "Epoch 213/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4856118.5000 - mae: 1693.6129 - mse: 4856118.5000 - val_loss: 4437059.5000 - val_mae: 1602.5504 - val_mse: 4437059.5000\n",
      "Epoch 214/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4831676.0000 - mae: 1689.7015 - mse: 4831676.0000 - val_loss: 4413317.0000 - val_mae: 1598.4985 - val_mse: 4413317.0000\n",
      "Epoch 215/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4809336.0000 - mae: 1686.2388 - mse: 4809336.0000 - val_loss: 4388069.0000 - val_mae: 1595.1172 - val_mse: 4388069.0000\n",
      "Epoch 216/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4788281.5000 - mae: 1682.6040 - mse: 4788281.5000 - val_loss: 4370286.5000 - val_mae: 1591.6038 - val_mse: 4370286.5000\n",
      "Epoch 217/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4765596.5000 - mae: 1678.9156 - mse: 4765596.5000 - val_loss: 4344265.5000 - val_mae: 1586.8008 - val_mse: 4344265.5000\n",
      "Epoch 218/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4747044.0000 - mae: 1675.4683 - mse: 4747044.0000 - val_loss: 4309994.5000 - val_mae: 1581.4539 - val_mse: 4309994.5000\n",
      "Epoch 219/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4729231.5000 - mae: 1672.4937 - mse: 4729231.5000 - val_loss: 4310466.5000 - val_mae: 1580.1724 - val_mse: 4310466.5000\n",
      "Epoch 220/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4704490.0000 - mae: 1668.3005 - mse: 4704490.0000 - val_loss: 4285112.5000 - val_mae: 1576.9315 - val_mse: 4285112.5000\n",
      "Epoch 221/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4685507.0000 - mae: 1665.0303 - mse: 4685507.0000 - val_loss: 4267321.5000 - val_mae: 1573.1101 - val_mse: 4267321.5000\n",
      "Epoch 222/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4664373.0000 - mae: 1661.4481 - mse: 4664373.0000 - val_loss: 4241078.0000 - val_mae: 1568.8878 - val_mse: 4241078.0000\n",
      "Epoch 223/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4646758.5000 - mae: 1658.0991 - mse: 4646758.5000 - val_loss: 4224010.5000 - val_mae: 1564.6554 - val_mse: 4224010.5000\n",
      "Epoch 224/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4627886.5000 - mae: 1655.4297 - mse: 4627886.5000 - val_loss: 4204745.0000 - val_mae: 1563.0214 - val_mse: 4204745.0000\n",
      "Epoch 225/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4608490.0000 - mae: 1651.9327 - mse: 4608490.0000 - val_loss: 4180393.5000 - val_mae: 1560.0704 - val_mse: 4180393.5000\n",
      "Epoch 226/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4588938.0000 - mae: 1649.0435 - mse: 4588938.0000 - val_loss: 4164021.5000 - val_mae: 1556.3762 - val_mse: 4164021.5000\n",
      "Epoch 227/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4572930.5000 - mae: 1646.1237 - mse: 4572930.5000 - val_loss: 4150411.7500 - val_mae: 1553.6439 - val_mse: 4150411.7500\n",
      "Epoch 228/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4554512.0000 - mae: 1643.0778 - mse: 4554512.0000 - val_loss: 4132925.7500 - val_mae: 1551.3840 - val_mse: 4132925.7500\n",
      "Epoch 229/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4536174.0000 - mae: 1640.0203 - mse: 4536174.0000 - val_loss: 4109393.2500 - val_mae: 1547.8828 - val_mse: 4109393.2500\n",
      "Epoch 230/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4519354.5000 - mae: 1636.9958 - mse: 4519354.5000 - val_loss: 4093226.5000 - val_mae: 1545.6168 - val_mse: 4093226.5000\n",
      "Epoch 231/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4502606.5000 - mae: 1634.3551 - mse: 4502606.5000 - val_loss: 4070877.0000 - val_mae: 1541.9221 - val_mse: 4070877.0000\n",
      "Epoch 232/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4483455.0000 - mae: 1631.4520 - mse: 4483455.0000 - val_loss: 4065574.5000 - val_mae: 1542.9052 - val_mse: 4065574.5000\n",
      "Epoch 233/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4465966.0000 - mae: 1628.1553 - mse: 4465966.0000 - val_loss: 4039796.2500 - val_mae: 1538.2831 - val_mse: 4039796.2500\n",
      "Epoch 234/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4449632.5000 - mae: 1625.2817 - mse: 4449632.5000 - val_loss: 4036627.0000 - val_mae: 1537.6614 - val_mse: 4036627.0000\n",
      "Epoch 235/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4433292.0000 - mae: 1622.5734 - mse: 4433292.0000 - val_loss: 4020847.2500 - val_mae: 1536.2917 - val_mse: 4020847.2500\n",
      "Epoch 236/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4416884.5000 - mae: 1619.6484 - mse: 4416884.5000 - val_loss: 3996761.0000 - val_mae: 1531.9911 - val_mse: 3996761.0000\n",
      "Epoch 237/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4399900.0000 - mae: 1616.7365 - mse: 4399900.0000 - val_loss: 3984756.0000 - val_mae: 1531.3408 - val_mse: 3984756.0000\n",
      "Epoch 238/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4385517.0000 - mae: 1614.0908 - mse: 4385517.0000 - val_loss: 3967095.7500 - val_mae: 1528.6472 - val_mse: 3967095.7500\n",
      "Epoch 239/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4369140.0000 - mae: 1611.1608 - mse: 4369140.0000 - val_loss: 3951502.7500 - val_mae: 1525.9437 - val_mse: 3951502.7500\n",
      "Epoch 240/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4356276.0000 - mae: 1609.0231 - mse: 4356276.0000 - val_loss: 3935903.2500 - val_mae: 1522.3486 - val_mse: 3935903.2500\n",
      "Epoch 241/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4343798.5000 - mae: 1606.7350 - mse: 4343798.5000 - val_loss: 3920970.5000 - val_mae: 1522.5248 - val_mse: 3920970.5000\n",
      "Epoch 242/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4325083.5000 - mae: 1603.5355 - mse: 4325083.5000 - val_loss: 3907235.0000 - val_mae: 1519.2186 - val_mse: 3907235.0000\n",
      "Epoch 243/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4310823.0000 - mae: 1600.8110 - mse: 4310823.0000 - val_loss: 3891006.2500 - val_mae: 1516.9827 - val_mse: 3891006.2500\n",
      "Epoch 244/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4296615.0000 - mae: 1598.0703 - mse: 4296615.0000 - val_loss: 3876203.2500 - val_mae: 1514.8146 - val_mse: 3876203.2500\n",
      "Epoch 245/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4282092.5000 - mae: 1595.5419 - mse: 4282092.5000 - val_loss: 3867021.0000 - val_mae: 1513.4957 - val_mse: 3867021.0000\n",
      "Epoch 246/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4269771.5000 - mae: 1593.0186 - mse: 4269771.5000 - val_loss: 3857731.0000 - val_mae: 1512.4525 - val_mse: 3857731.0000\n",
      "Epoch 247/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4257976.5000 - mae: 1590.9705 - mse: 4257976.5000 - val_loss: 3839924.7500 - val_mae: 1510.2354 - val_mse: 3839924.7500\n",
      "Epoch 248/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4243323.0000 - mae: 1588.1199 - mse: 4243323.0000 - val_loss: 3822286.2500 - val_mae: 1507.7394 - val_mse: 3822286.2500\n",
      "Epoch 249/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4230716.0000 - mae: 1586.1820 - mse: 4230716.0000 - val_loss: 3818394.0000 - val_mae: 1507.1053 - val_mse: 3818394.0000\n",
      "Epoch 250/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4217972.5000 - mae: 1583.7308 - mse: 4217972.5000 - val_loss: 3797461.2500 - val_mae: 1504.6283 - val_mse: 3797461.2500\n",
      "Epoch 251/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4203782.5000 - mae: 1580.9397 - mse: 4203782.5000 - val_loss: 3778226.2500 - val_mae: 1501.9730 - val_mse: 3778226.2500\n",
      "Epoch 252/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4192641.0000 - mae: 1579.1624 - mse: 4192641.0000 - val_loss: 3779464.2500 - val_mae: 1502.6725 - val_mse: 3779464.2500\n",
      "Epoch 253/300\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 4178990.5000 - mae: 1576.7031 - mse: 4178990.5000 - val_loss: 3760182.5000 - val_mae: 1499.4073 - val_mse: 3760182.5000\n",
      "Epoch 254/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4166876.5000 - mae: 1574.3481 - mse: 4166876.5000 - val_loss: 3752842.7500 - val_mae: 1498.5348 - val_mse: 3752842.7500\n",
      "Epoch 255/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4156070.7500 - mae: 1572.6613 - mse: 4156070.7500 - val_loss: 3738167.0000 - val_mae: 1494.6626 - val_mse: 3738167.0000\n",
      "Epoch 256/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4143551.2500 - mae: 1570.1687 - mse: 4143551.2500 - val_loss: 3720816.5000 - val_mae: 1493.2877 - val_mse: 3720816.5000\n",
      "Epoch 257/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4132326.2500 - mae: 1567.8759 - mse: 4132326.2500 - val_loss: 3708959.2500 - val_mae: 1489.9113 - val_mse: 3708959.2500\n",
      "Epoch 258/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4118894.7500 - mae: 1565.4222 - mse: 4118894.7500 - val_loss: 3698833.2500 - val_mae: 1489.0559 - val_mse: 3698833.2500\n",
      "Epoch 259/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4108278.0000 - mae: 1563.4502 - mse: 4108278.0000 - val_loss: 3686762.0000 - val_mae: 1487.8691 - val_mse: 3686762.0000\n",
      "Epoch 260/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4097301.2500 - mae: 1561.2849 - mse: 4097301.2500 - val_loss: 3675467.7500 - val_mae: 1485.0608 - val_mse: 3675467.7500\n",
      "Epoch 261/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4087124.0000 - mae: 1560.0156 - mse: 4087124.0000 - val_loss: 3676367.5000 - val_mae: 1485.2791 - val_mse: 3676367.5000\n",
      "Epoch 262/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4077307.7500 - mae: 1557.4565 - mse: 4077307.7500 - val_loss: 3651552.5000 - val_mae: 1483.0109 - val_mse: 3651552.5000\n",
      "Epoch 263/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4064176.0000 - mae: 1554.8610 - mse: 4064176.0000 - val_loss: 3639648.7500 - val_mae: 1479.8036 - val_mse: 3639648.7500\n",
      "Epoch 264/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4053469.0000 - mae: 1552.7850 - mse: 4053469.0000 - val_loss: 3632961.7500 - val_mae: 1478.2122 - val_mse: 3632961.7500\n",
      "Epoch 265/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4045691.2500 - mae: 1551.0461 - mse: 4045691.2500 - val_loss: 3625020.2500 - val_mae: 1478.0774 - val_mse: 3625020.2500\n",
      "Epoch 266/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4033111.5000 - mae: 1548.8010 - mse: 4033111.5000 - val_loss: 3618458.5000 - val_mae: 1476.7585 - val_mse: 3618458.5000\n",
      "Epoch 267/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4022592.7500 - mae: 1546.8514 - mse: 4022592.7500 - val_loss: 3611338.5000 - val_mae: 1475.5669 - val_mse: 3611338.5000\n",
      "Epoch 268/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4014587.0000 - mae: 1545.2360 - mse: 4014587.0000 - val_loss: 3593356.2500 - val_mae: 1472.9957 - val_mse: 3593356.2500\n",
      "Epoch 269/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4001832.5000 - mae: 1542.8019 - mse: 4001832.5000 - val_loss: 3587338.5000 - val_mae: 1471.8350 - val_mse: 3587338.5000\n",
      "Epoch 270/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 3993001.5000 - mae: 1540.7974 - mse: 3993001.5000 - val_loss: 3572499.7500 - val_mae: 1469.4479 - val_mse: 3572499.7500\n",
      "Epoch 271/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 3983163.0000 - mae: 1538.9789 - mse: 3983163.0000 - val_loss: 3569548.0000 - val_mae: 1468.7292 - val_mse: 3569548.0000\n",
      "Epoch 272/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 3973885.2500 - mae: 1537.4600 - mse: 3973885.2500 - val_loss: 3558563.5000 - val_mae: 1466.7401 - val_mse: 3558563.5000\n",
      "Epoch 273/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 3964238.2500 - mae: 1535.6420 - mse: 3964238.2500 - val_loss: 3555348.2500 - val_mae: 1466.3690 - val_mse: 3555348.2500\n",
      "Epoch 274/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 3954022.5000 - mae: 1533.6881 - mse: 3954022.5000 - val_loss: 3551525.0000 - val_mae: 1465.8021 - val_mse: 3551525.0000\n",
      "Epoch 275/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 3946484.5000 - mae: 1531.8943 - mse: 3946484.5000 - val_loss: 3539791.0000 - val_mae: 1463.9332 - val_mse: 3539791.0000\n",
      "Epoch 276/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 3940006.0000 - mae: 1530.2645 - mse: 3940006.0000 - val_loss: 3536752.5000 - val_mae: 1463.8511 - val_mse: 3536752.5000\n",
      "Epoch 277/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 3929826.0000 - mae: 1528.6395 - mse: 3929826.0000 - val_loss: 3524275.0000 - val_mae: 1462.4512 - val_mse: 3524275.0000\n",
      "Epoch 278/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 3919097.5000 - mae: 1526.6162 - mse: 3919097.5000 - val_loss: 3510678.5000 - val_mae: 1460.3322 - val_mse: 3510678.5000\n",
      "Epoch 279/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 3911128.2500 - mae: 1524.9055 - mse: 3911128.2500 - val_loss: 3509400.7500 - val_mae: 1458.9889 - val_mse: 3509400.7500\n",
      "Epoch 280/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 3903528.7500 - mae: 1523.2278 - mse: 3903528.7500 - val_loss: 3507577.0000 - val_mae: 1459.2295 - val_mse: 3507577.0000\n",
      "Epoch 281/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 3891765.0000 - mae: 1520.9823 - mse: 3891765.0000 - val_loss: 3499768.2500 - val_mae: 1457.8245 - val_mse: 3499768.2500\n",
      "Epoch 282/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3884533.2500 - mae: 1519.7673 - mse: 3884533.2500 - val_loss: 3485036.2500 - val_mae: 1455.8641 - val_mse: 3485036.2500\n",
      "Epoch 283/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 3877633.2500 - mae: 1518.6326 - mse: 3877633.2500 - val_loss: 3489076.0000 - val_mae: 1456.6554 - val_mse: 3489076.0000\n",
      "Epoch 284/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 3868023.0000 - mae: 1516.7876 - mse: 3868023.0000 - val_loss: 3472017.5000 - val_mae: 1454.3597 - val_mse: 3472017.5000\n",
      "Epoch 285/300\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 3858554.5000 - mae: 1514.7318 - mse: 3858554.5000 - val_loss: 3467475.5000 - val_mae: 1452.6146 - val_mse: 3467475.5000\n",
      "Epoch 286/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3853644.2500 - mae: 1513.3649 - mse: 3853644.2500 - val_loss: 3464071.7500 - val_mae: 1452.2363 - val_mse: 3464072.0000\n",
      "Epoch 287/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 3844678.5000 - mae: 1511.7094 - mse: 3844678.5000 - val_loss: 3454277.5000 - val_mae: 1450.1820 - val_mse: 3454277.5000\n",
      "Epoch 288/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 3838345.7500 - mae: 1509.9988 - mse: 3838345.7500 - val_loss: 3440855.2500 - val_mae: 1447.8499 - val_mse: 3440855.2500\n",
      "Epoch 289/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3831656.0000 - mae: 1509.9497 - mse: 3831656.0000 - val_loss: 3450747.7500 - val_mae: 1451.0902 - val_mse: 3450747.7500\n",
      "Epoch 290/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3820208.0000 - mae: 1507.0786 - mse: 3820208.0000 - val_loss: 3440224.5000 - val_mae: 1447.8878 - val_mse: 3440224.5000\n",
      "Epoch 291/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 3813568.5000 - mae: 1506.1178 - mse: 3813568.5000 - val_loss: 3443537.5000 - val_mae: 1448.8071 - val_mse: 3443537.5000\n",
      "Epoch 292/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 3808099.0000 - mae: 1504.4722 - mse: 3808099.0000 - val_loss: 3420982.7500 - val_mae: 1444.6810 - val_mse: 3420982.7500\n",
      "Epoch 293/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3799899.5000 - mae: 1502.9860 - mse: 3799899.5000 - val_loss: 3413231.5000 - val_mae: 1442.7542 - val_mse: 3413231.5000\n",
      "Epoch 294/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3794067.7500 - mae: 1501.9177 - mse: 3794067.7500 - val_loss: 3426971.2500 - val_mae: 1446.2021 - val_mse: 3426971.2500\n",
      "Epoch 295/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 3785974.5000 - mae: 1500.3679 - mse: 3785974.5000 - val_loss: 3411959.2500 - val_mae: 1443.6633 - val_mse: 3411959.2500\n",
      "Epoch 296/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 3781101.2500 - mae: 1499.5864 - mse: 3781101.2500 - val_loss: 3405068.5000 - val_mae: 1440.9834 - val_mse: 3405068.5000\n",
      "Epoch 297/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 3774429.2500 - mae: 1497.8112 - mse: 3774429.2500 - val_loss: 3385536.2500 - val_mae: 1438.8256 - val_mse: 3385536.2500\n",
      "Epoch 298/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 3767562.0000 - mae: 1496.5715 - mse: 3767562.0000 - val_loss: 3400054.2500 - val_mae: 1441.2837 - val_mse: 3400054.2500\n",
      "Epoch 299/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3757009.0000 - mae: 1494.6219 - mse: 3757009.0000 - val_loss: 3384191.2500 - val_mae: 1438.0026 - val_mse: 3384191.2500\n",
      "Epoch 300/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3751593.7500 - mae: 1493.2175 - mse: 3751593.7500 - val_loss: 3378197.5000 - val_mae: 1436.4181 - val_mse: 3378197.5000\n",
      "Final Root Mean Square Error on validation set: 1837.987\n"
     ]
    }
   ],
   "source": [
    "class check(keras.callbacks.Callback):\n",
    "    def epoch_end(self, epoch, logs):\n",
    "        if epoch % 100 == 0: \n",
    "            print('.', end='')\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=15)\n",
    "history = model.fit(train_x, train_y, epochs=300, verbose=1, validation_split = 0.1,\n",
    "                    callbacks=[early_stop, check()])\n",
    "\n",
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "\n",
    "rmse_final = np.sqrt(float(hist['val_mse'].tail(1)))\n",
    "print('Final Root Mean Square Error on validation set: {}'.format(round(rmse_final, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "809d32ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      1.148052e+08\n",
      "1      1.147914e+08\n",
      "2      1.147739e+08\n",
      "3      1.147475e+08\n",
      "4      1.147075e+08\n",
      "           ...     \n",
      "295    3.405068e+06\n",
      "296    3.385536e+06\n",
      "297    3.400054e+06\n",
      "298    3.384191e+06\n",
      "299    3.378198e+06\n",
      "Name: val_mse, Length: 300, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(hist['val_mse'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c31a1c3a",
   "metadata": {},
   "source": [
    "Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9bff775e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Model loss')\n",
    "plt.ylabel('Value of error')\n",
    "plt.xlabel('Epochs')\n",
    "plt.plot(hist['loss'], label='Training error')\n",
    "plt.plot(hist['val_loss'], label='Validation error')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c4bdcc8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 2ms/step - loss: 4467540.5000 - mae: 1618.0087 - mse: 4467540.5000\n",
      "Root Mean Square Error on test set: 2113.66\n",
      "Accuracy: 79.5%\n"
     ]
    }
   ],
   "source": [
    "test_x_norm = (test_x - train_mean) / train_std\n",
    "mse, _, _ = model.evaluate(test_x_norm, test_y)\n",
    "rmse = np.sqrt(mse)\n",
    "acc = float((1-rmse/10312.08)*100)\n",
    "print('Root Mean Square Error on test set: {}'.format(round(rmse, 2)))\n",
    "print('Accuracy: {}%'.format(round(acc, 2)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
